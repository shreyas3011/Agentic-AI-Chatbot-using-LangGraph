{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0574f87",
   "metadata": {},
   "source": [
    "Tools Generating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a75df61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import ArxivQueryRun, WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper,ArxivAPIWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71be0482",
   "metadata": {},
   "source": [
    "**generating arxiv tool**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arxiv\n"
     ]
    }
   ],
   "source": [
    "api_wrapper_arxiv= ArxivAPIWrapper(top_k_results=2,doc_content_chars_max=500)\n",
    "arxiv= ArxivQueryRun(api_wrapper=api_wrapper_arxiv,description=\"query arxiv papers\")\n",
    "print(arxiv.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Published: 2021-05-06\\nTitle: Do You Even Need Attention? A Stack of Feed-Forward Layers Does Surprisingly Well on ImageNet\\nAuthors: Luke Melas-Kyriazi\\nSummary: The strong performance of vision transformers on image classification and other vision tasks is often attributed to the design of their multi-head attention layers. However, the extent to which attention is responsible for this strong performance remains unclear. In this short report, we ask: is the attention layer even necessary? Specifi'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv.invoke(\"attention all you need\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074a5149",
   "metadata": {},
   "source": [
    "**generating wikipedia tool**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f979be0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wikipedia\n"
     ]
    }
   ],
   "source": [
    "api_wrapper_wiki=WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=500)\n",
    "wiki=WikipediaQueryRun(api_wrapper=api_wrapper_wiki)\n",
    "print(wiki.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: Artificial intelligence\\nSummary: Artificial intelligence (AI) is the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goal'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki.invoke(\"Artificial Intelligence\")\n",
    "\n",
    "#now we done with tools importing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"]=os.getenv(\"TAVILY_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16209/3543858584.py:2: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the `langchain-tavily package and should be used instead. To use it run `pip install -U `langchain-tavily` and import as `from `langchain_tavily import TavilySearch``.\n",
      "  tavily=TavilySearchResults()\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "tavily=TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': \"Google's year in review: 8 areas with research breakthroughs in 2025\",\n",
       "  'url': 'https://blog.google/innovation-and-ai/products/2025-research-breakthroughs/',\n",
       "  'content': 'In 2025, Google made significant AI research breakthroughs with models like Gemini 3 and Gemma 3. These advancements improved AI\\'s reasoning, multimodality, and efficiency, leading to new products and features across Google\\'s portfolio. Expect more AI-driven innovations in science, computing, and tools for global challenges as Google prioritizes responsible AI development and collaboration.\\n\\n## Bullet points [...] ## Bullet points\\n\\n \"Google\\'s year in review: 8 areas with research breakthroughs in 2025\" highlights AI advancements and more.\\n Gemini 3 models showed big leaps in reasoning, multimodality, efficiency, and creative abilities.\\n AI is transforming Google\\'s products, from Pixel 10 to Search, with agentic capabilities.\\n AI is boosting science, from genomics and healthcare to math, coding, and quantum computing.\\n Google is prioritizing AI safety, collaboration, and addressing global challenges like climate change.\\n\\n## Basic explainer [...] Learn more:\\n\\nLearn more:\\n\\nLearn more:\\n\\nLearn more:\\n\\nLearn more:\\n\\nLearn more:\\n\\n# Google\\'s year in review: 8 areas with research breakthroughs in 2025\\n\\nDec 23, 2025\\n\\nThis was a year of AI agents, reasoning and scientific discovery.\\n\\nJeff Dean\\nDemis_headshot\\n2024 Headshot for James Manyika\\n\\n## General summary\\n\\nIn 2025, Google made significant AI research breakthroughs with models like Gemini 3 and Gemma 3. These advancements improved AI\\'s reasoning, multimodality, and efficiency, leading to new products and features across Google\\'s portfolio. Expect more AI-driven innovations in science, computing, and tools for global challenges as Google prioritizes responsible AI development and collaboration.',\n",
       "  'score': 0.9992679},\n",
       " {'title': 'Advancements in AI and Machine Learning',\n",
       "  'url': 'https://ep.jhu.edu/news/advancements-in-ai-and-machine-learning/',\n",
       "  'content': '2020s: Emergence of Generative AI Models like GPT-3 and DALL·E enabled AI to generate human-like text and create images from textual descriptions. [...] ## Recent Advancements in AI and Machine Learning\\n\\nThe advancements in AI and ML have exponentially enhanced applications across multiple sectors. Here’s how AI and ML have changed various industries.\\n\\n### Breakthroughs in Generative AI and Large Language Models\\n\\nThe field of generative AI has seen remarkable progress, particularly with the development of advanced Large Language Models (LLMs). Meta’s recent release of Llama 4 includes models like Scout and Maverick that are designed to handle politically and socially contentious questions more effectively than their predecessors. They demonstrate reduced political bias and can process diverse data types, including text, video, images, and audio. \\u200b [...] Computational power: The computational resources used to train AI models have been increasing exponentially, with estimates indicating a 4-5x annual growth rate from 2010 to 2024. \\u200b\\n Training data volume: The size of datasets employed for training language models has grown approximately 2.9 times per year since 2010, reflecting an increased demand for extensive data to enhance AI capabilities. \\u200b\\n Algorithmic advancements: Innovations in algorithms have significantly boosted AI performance to solve complex problems more efficiently.\\n\\n### Skills in Demand for the AI Age\\n\\nDeveloping the following competencies can help you navigate and contribute to the evolving technological landscape:',\n",
       "  'score': 0.9979493},\n",
       " {'title': \"What's next in AI: 7 trends to watch in 2026 - Microsoft Source\",\n",
       "  'url': 'https://news.microsoft.com/source/features/ai/whats-next-in-ai-7-trends-to-watch-in-2026/',\n",
       "  'content': '## AI will become central to the research process\\n\\n AI is already speeding up breakthroughs in fields like climate modeling, molecular dynamics and materials design, says Peter Lee, president of Microsoft Research. But the next leap is coming. In 2026, AI won’t just summarize papers, answer questions and write reports — it will actively join the process of discovery in physics, chemistry and biology.\\n\\n“AI will generate hypotheses, use tools and apps that control scientific experiments, and collaborate with both human and AI research colleagues,” Lee says. [...] This shift is creating a world where every research scientist soon could have an AI lab assistant that can suggest new experiments and even run parts of them. That’s the logical next step, Lee says, building on how AI works alongside developers with “pair programming,” for example, and uses apps to automate everyday tasks like shopping and scheduling in other domains.\\n\\nIt’s a transformation that promises to accelerate research and change how scientific discoveries are made, he says.\\n\\n## AI infrastructure will get smarter and more efficient [...] King points to achievements demonstrated in 2025 by Microsoft AI’s Diagnostic Orchestrator (MAI-DxO), which solved complex medical cases with 85.5% accuracy, far above the 20% average for experienced physicians. With Copilot and Bing already answering more than 50 million health questions daily, he sees advances in AI as a way to give people more influence and control over their own health and wellbeing.\\n\\n## AI will become central to the research process',\n",
       "  'score': 0.9974491},\n",
       " {'title': 'The 2025 AI Index Report | Stanford HAI',\n",
       "  'url': 'https://hai.stanford.edu/ai-index/2025-ai-index-report',\n",
       "  'content': '#### Chapter 1: Research and Development\\n\\nThis chapter explores trends in AI research and development, beginning with an analysis of AI publications, patents, and notable AI systems.\\n\\n#### Chapter 2: Technical Performance\\n\\nThe Technical Performance section of this year’s AI Index provides a comprehensive overview of AI advancements in 2024.\\n\\n#### Chapter 3: Responsible AI\\n\\nArtificial intelligence is now deeply integrated into nearly every aspect of our lives. It is reshaping sectors like education, finance, and healthcare, where algorithm-driven insights guide critical decisions.\\n\\n#### Chapter 4: Economy\\n\\nGlobal private AI investment hits record high...\\n\\n#### Chapter 5: Science and Medicine [...] In 2023, researchers introduced new benchmarks—MMMU, GPQA, and SWE-bench—to test the limits of advanced AI systems. Just a year later, performance sharply increased: scores rose by 18.8, 48.9, and 67.3 percentage points on MMMU, GPQA, and SWE-bench, respectively. Beyond benchmarks, AI systems made major strides in generating high-quality video, and in some settings, language model agents even outperformed humans in programming tasks with limited time budgets.\\n\\n### 2. AI is increasingly embedded in everyday life.',\n",
       "  'score': 0.9941801},\n",
       " {'title': 'The trends that will shape AI and tech in 2026 - IBM',\n",
       "  'url': 'https://www.ibm.com/think/news/ai-tech-trends-predictions-2026',\n",
       "  'content': '### Scaling will hit its limits, and physical AI will gain momentum | Peter Staar, Principal Research Staff Member, IBM Research Zurich; Chair of the Technical Steering Committee of Docling in the Linux Foundation for AI and Data\\n\\nIBM’s Peter Staar predicts 2026 will mark a shift in AI research priorities that favor the palpable. “Robotics and physical AI are definitely going to pick up,” he said. While large language models remain dominant, Staar notes that the industry is hitting diminishing returns from scaling. “People are getting tired of scaling and are looking for new ideas,” he explained.\\n\\nStaar sees a lot of interest for AI that can sense, act and learn in real environments; this is where the technical challenge will lie: this could be the next frontier for innovation. [...] 2024 ended on a high note for open-source AI with Meta’s Llama models gaining traction. Since then, the open-source AI ecosystem has grown a lot, with smaller, domain-specific models achieving impressive results—it’s the case for IBM’s Granite, Ai2’s Olmo 3 and, of course, DeepSeek’s models. Anthony Annunziata, Director of Open Source AI at IBM and the AI Alliance, sees this trend accelerating in 2026.\\n\\n“We’re going to see smaller reasoning models that are multimodal and easier to tune for specific domains,” he said during an interview with IBM Think. [...] Advances in fine‑tuning and reinforcement learning also mean that enterprises can adopt open-source AI, feeding the appetite for smaller and efficient models. “Instead of one giant model for everything, you’ll have smaller, more efficient models that are just as accurate—maybe more so—when tuned for the right use case,” he said.\\n\\nOpen source, agentic AI will accelerate this trend. “General‑purpose agents aren’t enough for legal, health or manufacturing,” Annunziata said. “You need domain‑enriched models and architectures that reflect expert workflows.”',\n",
       "  'score': 0.9881309}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tavily.invoke(\"Latest advancements in AI research\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "731d2b92",
   "metadata": {},
   "source": [
    "combining all tools into single variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[arxiv,wiki,tavily]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd36fa1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9d39532",
   "metadata": {},
   "source": [
    "intilize the llm model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm=ChatGroq(model=\"llama-3.1-8b-instant\",temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='AI, or Artificial Intelligence, refers to the simulation of human intelligence in machines that are programmed to think and learn like humans. The term can also be applied to any machine that exhibits traits associated with a human mind such as learning and problem-solving.\\n\\nAI technology is based on the principle of creating algorithms that can process data, identify patterns, and make decisions with minimal human intervention. This is achieved through various techniques, including:\\n\\n1. **Machine Learning (ML)**: A subset of AI that involves training algorithms on data to enable them to learn and improve their performance over time.\\n2. **Deep Learning (DL)**: A type of ML that uses neural networks with multiple layers to analyze and interpret data.\\n3. **Natural Language Processing (NLP)**: A field of AI that deals with the interaction between computers and humans in natural language.\\n4. **Computer Vision**: A field of AI that enables computers to interpret and understand visual data from images and videos.\\n\\nAI has numerous applications across various industries, including:\\n\\n1. **Virtual Assistants**: AI-powered virtual assistants, such as Siri, Alexa, and Google Assistant, can perform tasks, answer questions, and provide information.\\n2. **Image Recognition**: AI-powered image recognition can identify objects, people, and patterns in images and videos.\\n3. **Predictive Maintenance**: AI-powered predictive maintenance can analyze data from sensors and equipment to predict when maintenance is required.\\n4. **Healthcare**: AI can analyze medical data, diagnose diseases, and develop personalized treatment plans.\\n5. **Autonomous Vehicles**: AI can control self-driving cars, trucks, and drones.\\n6. **Customer Service**: AI-powered chatbots can provide customer support and answer frequently asked questions.\\n7. **Cybersecurity**: AI can detect and prevent cyber threats in real-time.\\n\\nThe benefits of AI include:\\n\\n1. **Increased Efficiency**: AI can automate repetitive tasks, freeing up human resources for more strategic and creative work.\\n2. **Improved Accuracy**: AI can analyze large amounts of data and make decisions with high accuracy.\\n3. **Enhanced Customer Experience**: AI can provide personalized experiences and improve customer satisfaction.\\n4. **Cost Savings**: AI can reduce costs by automating tasks, improving efficiency, and reducing errors.\\n\\nHowever, AI also raises concerns about:\\n\\n1. **Job Displacement**: AI may displace human workers in certain industries.\\n2. **Bias and Fairness**: AI systems can perpetuate biases and discriminate against certain groups.\\n3. **Security Risks**: AI systems can be vulnerable to cyber attacks and data breaches.\\n4. **Ethical Concerns**: AI raises questions about accountability, transparency, and the potential for AI to make decisions that harm humans.\\n\\nOverall, AI has the potential to revolutionize various industries and aspects of our lives, but it also requires careful consideration of its benefits and risks.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 573, 'prompt_tokens': 38, 'total_tokens': 611, 'completion_time': 0.734057426, 'completion_tokens_details': None, 'prompt_time': 0.001779423, 'prompt_tokens_details': None, 'queue_time': 0.144669177, 'total_time': 0.735836849}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f757f4b0bf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019bf9fc-0f1f-7830-a7d4-95800f22eee2-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 38, 'output_tokens': 573, 'total_tokens': 611})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"what is ai\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect the tools with     the llm \n",
    "llm_with_tools=llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '855btk166', 'function': {'arguments': '{\"query\":\"latest news on AI\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 459, 'total_tokens': 480, 'completion_time': 0.03813202, 'completion_tokens_details': None, 'prompt_time': 0.093212513, 'prompt_tokens_details': None, 'queue_time': 0.055990488, 'total_time': 0.131344533}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019bfa05-3f06-7102-9ea5-4643baaa8df6-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'latest news on AI'}, 'id': '855btk166', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 459, 'output_tokens': 21, 'total_tokens': 480})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(\"what is latest news on ai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c61962",
   "metadata": {},
   "source": [
    "** now we build our agentic application**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import AnyMessage\n",
    "from typing import Annotated\n",
    "from langgraph.graph.message import add_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class state(TypedDict):\n",
    "    messages:Annotated[list[AnyMessage],add_messages]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display,Image\n",
    "from langgraph.graph import StateGraph,START,END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
